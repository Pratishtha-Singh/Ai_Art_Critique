{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3728387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Faiss vector store\n",
    "import faiss\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8b57564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1660 artworks\n",
      "Sample metadata: {'artist': 'aaron siskind', 'title': 'acolman-1-1955', 'year': nan, 'dataset_source': 'WikiArt_ArtEmis'}\n",
      "Text embedding shape: (128,)\n",
      "Image embedding shape: (512,)\n"
     ]
    }
   ],
   "source": [
    "# Parse embeddings from string to numpy arrays\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def parse_embedding(emb_str):\n",
    "    if pd.isna(emb_str) or emb_str == '':\n",
    "        return np.array([])\n",
    "    # Remove brackets and split by spaces\n",
    "    emb_str = emb_str.strip('[]')\n",
    "    values = [float(x) for x in emb_str.split()]\n",
    "    return np.array(values)\n",
    "\n",
    "# Load the embedded dataset\n",
    "df = pd.read_csv('../data/04_feature/embedded_art_dataset.csv')\n",
    "\n",
    "df['text_embedding'] = df['text_embedding'].apply(parse_embedding)\n",
    "df['image_embedding'] = df['image_embedding'].apply(parse_embedding)\n",
    "\n",
    "# Extract relevant columns\n",
    "text_embeddings = df['text_embedding'].tolist()\n",
    "image_embeddings = df['image_embedding'].tolist()\n",
    "metadata = df[['artist', 'title', 'year', 'dataset_source']].to_dict('records')\n",
    "\n",
    "print(f\"Loaded {len(df)} artworks\")\n",
    "print(\"Sample metadata:\", metadata[0])\n",
    "print(\"Text embedding shape:\", text_embeddings[0].shape if text_embeddings[0].size > 0 else 0)\n",
    "print(\"Image embedding shape:\", image_embeddings[0].shape if image_embeddings[0].size > 0 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f4205c",
   "metadata": {},
   "source": [
    "## Step 2: Prepare Data for Indexing\n",
    "\n",
    "- **Combine Embeddings**: Concatenate text (128-dim) and image (512-dim) embeddings into 640-dim vectors for multimodal search. Pad with zeros if one is missing.\n",
    "- **Normalize**: Apply L2 normalization for cosine similarity in vector search.\n",
    "- **Metadata**: Already prepared as list of dicts with artist, title, year, dataset_source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82bf0f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 1660 combined embeddings\n",
      "Combined embedding shape: (640,)\n",
      "Sample normalized embedding norm: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for indexing\n",
    "import numpy as np\n",
    "\n",
    "# Strategy: Concatenate text and image embeddings for multimodal search\n",
    "combined_embeddings = []\n",
    "for text_emb, image_emb in zip(text_embeddings, image_embeddings):\n",
    "    if text_emb.size > 0 and image_emb.size > 0:\n",
    "        combined = np.concatenate([text_emb, image_emb])\n",
    "    elif text_emb.size > 0:\n",
    "        combined = np.concatenate([text_emb, np.zeros(512)])  # Pad with zeros if no image\n",
    "    elif image_emb.size > 0:\n",
    "        combined = np.concatenate([np.zeros(128), image_emb])  # Pad with zeros if no text\n",
    "    else:\n",
    "        combined = np.zeros(128 + 512)\n",
    "    combined_embeddings.append(combined)\n",
    "\n",
    "# Normalize embeddings for cosine similarity\n",
    "combined_embeddings = np.array(combined_embeddings)\n",
    "norms = np.linalg.norm(combined_embeddings, axis=1, keepdims=True)\n",
    "norms[norms == 0] = 1  # Avoid division by zero\n",
    "normalized_embeddings = combined_embeddings / norms\n",
    "\n",
    "# Metadata is already prepared as list of dicts\n",
    "print(f\"Prepared {len(normalized_embeddings)} combined embeddings\")\n",
    "print(\"Combined embedding shape:\", normalized_embeddings[0].shape)\n",
    "print(\"Sample normalized embedding norm:\", np.linalg.norm(normalized_embeddings[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2d63d0",
   "metadata": {},
   "source": [
    "## Step 3: Initialize Vector Store\n",
    "\n",
    "- **Faiss Setup**: Use IndexFlatIP for exact cosine similarity search on 640-dim normalized embeddings.\n",
    "- **Why Faiss**: Efficient, fast for small-to-medium datasets like 1.6k artworks, supports multimodal search without metadata storage (handled separately)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67ab4bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faiss index initialized with 1660 vectors\n",
      "Index dimension: 640\n"
     ]
    }
   ],
   "source": [
    "# Create Faiss index for cosine similarity (using inner product on normalized vectors)\n",
    "dimension = normalized_embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(dimension)  # Inner product for cosine similarity\n",
    "\n",
    "# Add normalized embeddings to the index\n",
    "index.add(normalized_embeddings.astype('float32'))\n",
    "\n",
    "print(f\"Faiss index initialized with {index.ntotal} vectors\")\n",
    "print(f\"Index dimension: {dimension}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdf74a8",
   "metadata": {},
   "source": [
    "## Step 4: Test Vector Search\n",
    "\n",
    "- **Query Example**: Search for the top 5 most similar artworks to the first one in the dataset.\n",
    "- **Faiss Search**: Use index.search() to find nearest neighbors by cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "796a2541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query artwork: {'artist': 'aaron siskind', 'title': 'acolman-1-1955', 'year': nan, 'dataset_source': 'WikiArt_ArtEmis'}\n",
      "\n",
      "Top 5 similar artworks:\n",
      "1. Distance: 1.0000\n",
      "   Metadata: {'artist': 'aaron siskind', 'title': 'acolman-1-1955', 'year': nan, 'dataset_source': 'WikiArt_ArtEmis'}\n",
      "\n",
      "2. Distance: 0.8372\n",
      "   Metadata: {'artist': 'howard hodgkin', 'title': 'all-alone-in-the-museum-of-art-1979', 'year': nan, 'dataset_source': 'WikiArt_ArtEmis'}\n",
      "\n",
      "3. Distance: 0.8356\n",
      "   Metadata: {'artist': 'aaron siskind', 'title': 'uruapan-11-1955', 'year': nan, 'dataset_source': 'WikiArt_ArtEmis'}\n",
      "\n",
      "4. Distance: 0.8344\n",
      "   Metadata: {'artist': 'edward corbett', 'title': 'untitled-1951', 'year': nan, 'dataset_source': 'WikiArt_ArtEmis'}\n",
      "\n",
      "5. Distance: 0.8255\n",
      "   Metadata: {'artist': 'jay defeo', 'title': 'origin-1956', 'year': nan, 'dataset_source': 'WikiArt_ArtEmis'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test search: Find top 5 similar artworks to the first one\n",
    "query_vector = normalized_embeddings[0:1].astype('float32')  # First vector as query\n",
    "distances, indices = index.search(query_vector, k=5)  # k=5 nearest neighbors\n",
    "\n",
    "print(\"Query artwork:\", metadata[0])\n",
    "print(\"\\nTop 5 similar artworks:\")\n",
    "for i, idx in enumerate(indices[0]):\n",
    "    print(f\"{i+1}. Distance: {distances[0][i]:.4f}\")\n",
    "    print(f\"   Metadata: {metadata[idx]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c934b7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faiss index saved to art_embeddings.index\n"
     ]
    }
   ],
   "source": [
    "# Save the Faiss index to disk\n",
    "faiss.write_index(index, \"art_embeddings.index\")\n",
    "print(\"Faiss index saved to art_embeddings.index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805b0e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load later: index = faiss.read_index(\"art_embeddings.index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcd8f33",
   "metadata": {},
   "source": [
    "## Step 5: Store Metadata\n",
    "\n",
    "Store Metadata:\n",
    "\n",
    "Ensure metadata is stored alongside embeddings for retrieval (e.g., artist, title, year, dataset_source).\n",
    "For FAISS, use a separate data structure (e.g., dict or list) to map indices to metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d2a7e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata saved to art_metadata.json\n",
      "Total metadata entries: 1660\n"
     ]
    }
   ],
   "source": [
    "# Save metadata to JSON for persistence\n",
    "import json\n",
    "\n",
    "with open(\"art_metadata.json\", \"w\") as f:\n",
    "    json.dump(metadata, f, indent=4)\n",
    "\n",
    "print(\"Metadata saved to art_metadata.json\")\n",
    "print(f\"Total metadata entries: {len(metadata)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0289cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load index and metadata for querying\n",
    "# index = faiss.read_index(\"art_embeddings.index\")\n",
    "# with open(\"art_metadata.json\", \"r\") as f:\n",
    "#     loaded_metadata = json.load(f)\n",
    "# print(f\"Loaded index with {index.ntotal} vectors and {len(loaded_metadata)} metadata entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6c81c8",
   "metadata": {},
   "source": [
    "## Step 6: Test Retrieval\n",
    "\n",
    "Test Retrieval:\n",
    "\n",
    "Implement a simple query function: Input a text query or image embedding, compute similarity, and return top-k results with metadata.\n",
    "Example queries: \"Find art similar to Van Gogh's style\" (encode query text/image and search)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b009d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query results:\n",
      "Distance: 0.5785, Artist: hans hofmann, Title: ecstasy-1947\n",
      "Distance: 0.5577, Artist: elaine de kooning, Title: glass-wall-1987\n",
      "Distance: 0.5564, Artist: manabu mabe, Title: passage-de-fuego-1961\n",
      "Distance: 0.5564, Artist: brett whiteley, Title: american-dream-1969\n",
      "Distance: 0.5557, Artist: bui xuan phai, Title: abstract(4)\n"
     ]
    }
   ],
   "source": [
    "# Load models for encoding queries\n",
    "from transformers import BertTokenizer, BertModel, CLIPProcessor, CLIPModel\n",
    "import torch\n",
    "\n",
    "# Load BERT for text\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('prajjwal1/bert-tiny')\n",
    "bert_model = BertModel.from_pretrained('prajjwal1/bert-tiny')\n",
    "\n",
    "# Load CLIP for images (if needed)\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "def encode_text(text):\n",
    "    inputs = bert_tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "def query_art(query_text, top_k=5):\n",
    "    # Encode query text\n",
    "    text_emb = encode_text(query_text)\n",
    "    \n",
    "    # Pad with zeros for image part\n",
    "    query_emb = np.concatenate([text_emb, np.zeros(512)])\n",
    "    \n",
    "    # Normalize\n",
    "    norm = np.linalg.norm(query_emb)\n",
    "    if norm > 0:\n",
    "        query_emb = query_emb / norm\n",
    "    \n",
    "    # Search\n",
    "    query_emb = query_emb.astype('float32').reshape(1, -1)\n",
    "    distances, indices = index.search(query_emb, k=top_k)\n",
    "    \n",
    "    # Return results\n",
    "    results = []\n",
    "    for i, idx in enumerate(indices[0]):\n",
    "        results.append({\n",
    "            'distance': distances[0][i],\n",
    "            'metadata': metadata[idx]\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# Example query\n",
    "results = query_art(\"Find art similar to Van Gogh's style\", top_k=5)\n",
    "print(\"Query results:\")\n",
    "for res in results:\n",
    "    print(f\"Distance: {res['distance']:.4f}, Artist: {res['metadata']['artist']}, Title: {res['metadata']['title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d111f5d",
   "metadata": {},
   "source": [
    "## Step 7: Persistence and Optimization\n",
    "\n",
    "Persistence and Optimization:\n",
    "\n",
    "Persist the vector store to disk (ChromaDB does this automatically; FAISS requires saving the index).\n",
    "Optimize for performance: Use approximate nearest neighbors if scaling up (e.g., FAISS IVF index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72f7d724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded index with 1660 vectors and 1660 metadata entries\n",
      "IVF index trained and saved for approximate search\n"
     ]
    }
   ],
   "source": [
    "# Persistence: Index and metadata are already saved\n",
    "# Demonstrate loading\n",
    "loaded_index = faiss.read_index(\"art_embeddings.index\")\n",
    "with open(\"art_metadata.json\", \"r\") as f:\n",
    "    loaded_metadata = json.load(f)\n",
    "print(f\"Loaded index with {loaded_index.ntotal} vectors and {len(loaded_metadata)} metadata entries\")\n",
    "\n",
    "# Optimization: For larger datasets, use IVF (Inverted File) for approximate search\n",
    "# Example: Create IVF index (nlist=100 clusters, suitable for ~10k vectors)\n",
    "nlist = 100  # Number of clusters\n",
    "quantizer = faiss.IndexFlatIP(dimension)  # Quantizer\n",
    "ivf_index = faiss.IndexIVFFlat(quantizer, dimension, nlist, faiss.METRIC_INNER_PRODUCT)\n",
    "\n",
    "# Train the index (required for IVF)\n",
    "ivf_index.train(normalized_embeddings.astype('float32'))\n",
    "ivf_index.add(normalized_embeddings.astype('float32'))\n",
    "\n",
    "# Save optimized index\n",
    "faiss.write_index(ivf_index, \"art_embeddings_ivf.index\")\n",
    "print(\"IVF index trained and saved for approximate search\")\n",
    "\n",
    "# Note: For small datasets like this (1660), IndexFlatIP is faster and exact.\n",
    "# Use IVF when dataset > 10k for better performance at slight accuracy cost."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
